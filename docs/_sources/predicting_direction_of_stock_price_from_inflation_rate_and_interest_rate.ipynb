{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1f90cb45bbbc67",
   "metadata": {},
   "source": [
    "## Predicting direction of stock price from interest rate and inflation rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82e39a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "_We utilized logistic regression to analyze the stock price data and provided a predictive model._\n",
    "\n",
    "by Allan Lee, Andy Zhang, Yi Yan and Chengyu Tao (DSCI 522 Group 3 Milestone 4)\n",
    "\n",
    "2023/12/09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f166af3ef293f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:35:10.185844Z",
     "start_time": "2023-11-23T03:35:10.149061Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from myst_nb import glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63270171-07bf-4690-86d5-dff5d7c73f86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dummy_model_score</th>\n      <th>logistic_regression_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.759259</td>\n      <td>0.753086</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "application/papermill.record/text/plain": "   dummy_model_score  logistic_regression_score\n0           0.759259                   0.753086"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "result_df"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>gspc</th>\n      <th>gspc_next_year_pct_chg</th>\n      <th>gspc_prev_year_pct_chg</th>\n      <th>inflation_rate_pct</th>\n      <th>inflation_rate_pct_chg</th>\n      <th>interest_rate_pct</th>\n      <th>interest_rate_pct_chg</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1955-07-31</td>\n      <td>43.520000</td>\n      <td>13.488049</td>\n      <td>40.932648</td>\n      <td>-0.371747</td>\n      <td>-0.371747</td>\n      <td>1.69</td>\n      <td>0.94</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1955-08-31</td>\n      <td>43.180000</td>\n      <td>10.027786</td>\n      <td>44.753605</td>\n      <td>0.373134</td>\n      <td>0.744882</td>\n      <td>2.00</td>\n      <td>0.62</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1955-09-30</td>\n      <td>43.669998</td>\n      <td>3.847035</td>\n      <td>35.159382</td>\n      <td>0.373134</td>\n      <td>1.113875</td>\n      <td>2.19</td>\n      <td>1.00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1955-10-31</td>\n      <td>42.340000</td>\n      <td>7.652342</td>\n      <td>33.648989</td>\n      <td>0.373134</td>\n      <td>0.744882</td>\n      <td>2.25</td>\n      <td>1.25</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1955-11-30</td>\n      <td>45.509998</td>\n      <td>-0.944840</td>\n      <td>32.914708</td>\n      <td>0.374532</td>\n      <td>1.118026</td>\n      <td>2.25</td>\n      <td>1.37</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "application/papermill.record/text/plain": "         date       gspc  gspc_next_year_pct_chg  gspc_prev_year_pct_chg  \\\n0  1955-07-31  43.520000               13.488049               40.932648   \n1  1955-08-31  43.180000               10.027786               44.753605   \n2  1955-09-30  43.669998                3.847035               35.159382   \n3  1955-10-31  42.340000                7.652342               33.648989   \n4  1955-11-30  45.509998               -0.944840               32.914708   \n\n   inflation_rate_pct  inflation_rate_pct_chg  interest_rate_pct  \\\n0           -0.371747               -0.371747               1.69   \n1            0.373134                0.744882               2.00   \n2            0.373134                1.113875               2.19   \n3            0.373134                0.744882               2.25   \n4            0.374532                1.118026               2.25   \n\n   interest_rate_pct_chg  target  \n0                   0.94    True  \n1                   0.62    True  \n2                   1.00    True  \n3                   1.25    True  \n4                   1.37   False  "
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "data_head"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df=pd.read_csv(\"../results/tables/mdl_result.csv\")[['dummy_model_precision_score (%)', 'logistic_regression_precision_score (%)']]\n",
    "glue(\"result_df\", result_df, display=False)\n",
    "\n",
    "data_head=pd.read_csv(\"../Data/Processed/processed_data.csv\").head(5)\n",
    "glue(\"data_head\", data_head, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ce1e26-d231-42c4-b51c-33753b220372",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dummy_model_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.759259</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "application/papermill.record/text/plain": "   dummy_model_score\n0           0.759259"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "dummy_mean_test_score"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>logistic_regression_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.753086</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "application/papermill.record/text/plain": "   logistic_regression_score\n0                   0.753086"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "regression_mean_test_score"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_mean_test_score = result_df[['dummy_model_precision_score (%)']]\n",
    "glue(\"dummy_mean_test_score\",dummy_mean_test_score, display=False)\n",
    "regression_mean_test_score = result_df[['logistic_regression_precision_score (%)']]\n",
    "glue(\"regression_mean_test_score\",regression_mean_test_score, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our exploration of the impact of inflation and interest rates on stock returns, we employed logistic regression to build a predictive model. The model, trained on data sourced from the S&P500, CPI, and Federal funds rate, exhibited reasonable performance. In the context, we want to make sure every positive prediction is accurate and choose the metric precision which focuses specifically on maximizing the true positive predictions among all the instances predicted as positive. \n",
    "\n",
    "Utilizing Python and packages such as Numpy, Pandas, Altair, and Scikit-learn, our analysis incorporated data preprocessing to address variations in sampling frequencies among S&P500 index, CPI, and interest rate data. Resampling to the last day of every month and filtering noise through monthly median calculations were crucial steps in preparing the data for effective analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f951a7cc0ff71d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In the context of the current financial landscape shaped by the COVID-19 pandemic, central banks globally responded by lowering interest rates to mitigate economic challenges. However, this led to heightened inflation due to increased consumer spending. In an effort to regain control and revert to pre-pandemic levels, central banks sharply raised interest rates to the highest point in 15 years. With over 50% of American households owning stocks {cite}`Caporal2023StockOwnership`, the team is keen to explore the impact of inflation and interest rates on stock returns. The pivotal question arises: Can we predict profitable outcomes in stock market index investments over a one-year period based on inflation and interest rate data? Recognizing the potential financial and emotional impact of losing investments and related mental health issues, the team prioritizes precision to minimize setbacks and maximize returns.\n",
    "\n",
    "\n",
    "\n",
    "## Methods \n",
    "### Data\n",
    "1. We decided to use the Standard & Poors 500 Index (S&P500) as stock market proxy. The index tracks stocks of 500 largest companies in USA. The price of S&P500 is obtained from Yahoo Finance {cite}`YahooFinanceSP500`.\n",
    "2. Inflation data is obtained from calculating the change of consumer price index (CPI) {cite}`YahooFinanceSP500`. We obtained United States CPI from the Federal Reserve Economic Data website and computed yearly inflation rate.\n",
    "3. We can use the Federal funds rate as proxy for interest rate. It is the target interest rate set by the Federal reserve for commercial banks to lend and borrow overnight. We obtained the Federal funds rate from the Federal Reserve Economic Data website.\n",
    "\n",
    "We derived the change in inflation rate and change in interest rate from the data we have as additional feature. We often hear on the news that inflation and interest rate are increasing or decreasing thus we thought these 2 features might provide additional predicting power for our model.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "The Python programming language {cite}`van1995python` and the following Python packages were used to perform the analysis:  Numpy {cite}`harris2020array`, Pandas {cite}`mckinney-proc-scipy-2010`, Altair {cite}`vanderplas2018altair`, Scikit-learn {cite}`pedregosa2011scikit`. The code used to perform the EDA and create the report which can be found here: https://github.com/UBC-MDS/dsci_522_group_3/tree/main.\n",
    "\n",
    "### Remarks\n",
    "S&P500 index, CPI, and Interest rate data we obtained have different sampling frequencies. CPI data has the lowest frequency and it is sampled every first day of the month. We decided to resample all data to last day of every month thus it is easy to calculate and interpret year-year and month-month change. Interest rate data was sampled daily and it is noisy. We decided to filter the data by taking monthly median during resampling. The following table summarizes how data preprocessing was done.\n",
    "\n",
    "\n",
    "| Data | Original sampling period | Preprocess procedure |\n",
    "| -------- | -------- | -------- |\n",
    "| S&P 500 Index | daily | Take the value from last day of month. If we do not have data for last day of month, use the data from the closest previous date |\n",
    "| CPI | first day of every month | Offset the date by 1 to last day of last month. We thought the value difference for 1 day is neglegible |\n",
    "| Interest Rate | daily | Resample to the last day of month by taking the median price of for every day of the month to filter for noise |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af48dad4f5f6fc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Read Data From Web\n",
    "\n",
    "The desciption of our data is shown below.\n",
    "\n",
    "#### columns\n",
    "| column name            | description                                                                                |\n",
    "|------------------------|--------------------------------------------------------------------------------------------|\n",
    "| gspc                   | price of S&P 500 stock index (will be ignored for model)                                   |\n",
    "| inflation_rate_pct     | 1 year inflation rate (12 months ago to now) (will be a feature for model)                 |\n",
    "| interest_rate_pct      | interest rate (will be a feature for model)                                                |                                           \n",
    "| inflation_rate_pct_chg | change of inflation between now and 12 months ago (will be a feature for model)            |       \n",
    "| interest_rate_pct_chg  | change of interest rate between now and 12 months ago (will be a feature for model)        |   \n",
    "| gspc_prev_year_chg_pct | change of gspc between now and 12 months ago (will be a feature for model)                 |            \n",
    "| gspc_next_year_pct_chg | change of gspc between now and 12 months later (will be used to get target)                | \n",
    "| target                 | whether gspc increased 12 months later compared to now (will be target for classification) |                      \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65676784-3106-4976-943a-3416f6831acc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{glue:figure} data_head\n",
    "---\n",
    "width: 200px\n",
    "name: \"data_head\"\n",
    "---\n",
    "Present the head of the processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18438180",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In our preliminary analysis, we find out:\n",
    "- No NA or missing data in dataset\n",
    "- One row record the observation for one month.\n",
    "- The time series data is from 1955-07 to 2022-10, which contains 808 observations.\n",
    "- The target is `True` when the stock price went up, and is `False` when the stock price went down.\n",
    "- The four columns `inflation_rate_pct`, `interest_rate_pct`,\n",
    "       `inflation_rate_pct_chg`, `interest_rate_pct_chg`,\n",
    "       `gspc_prev_year_pct_chg` are treated as features, and the target is treated as response in this binary classification problem. \n",
    "\n",
    "### Time Series Plots of Features\n",
    "\n",
    "The visualization of time series may reveal the pattern of data, we plot them as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe4d09-e433-4271-91c4-951877b6f03c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{figure} ../results/figures/time.png\n",
    "---\n",
    "width: 600px\n",
    "name: time series\n",
    "---\n",
    "Time Series Plots of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03c5f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Histograms of Features\n",
    "We plot the histograms to see the range and mode of interesting features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60126d4f-9eb9-4cb7-8637-51cb3046ddbe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{figure} ../results/figures/hist.png\n",
    "---\n",
    "width: 600px\n",
    "name: histogram\n",
    "---\n",
    "Histograms of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots of Feature Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6b7d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Spearmean's rank correlation test may reveal some potential correlation, we draw the scatterplots of following feature pairs:\n",
    "\n",
    "`interest_rate_pct vs inflation_rate_pct`\n",
    "\n",
    "`interest_rate_pct_chg vs inflation_rate_pct_chg`\n",
    "\n",
    "`inflation_rate_pct_chg vs inflation_rate_pct`\n",
    "\n",
    "`interest_rate_pct_chg vs interest_rate_pct`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fd920e-579c-4aab-af8d-d005e8c6ae94",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{figure} ../results/figures/scat.png\n",
    "---\n",
    "width: 600px\n",
    "name: scatter plot\n",
    "---\n",
    "Scatter plots of a few pairs of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396819ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Examine the data type for every column.\n",
    "- Illustrate the distribution of all numeric columns and investigate possible correlations between them.\n",
    "- Divide the dataframe into training and testing datasets with an 80:20 ratio.\n",
    "- Based on the histograms of all columns, the five numerical columns 'inflation_rate_pct', 'interest_rate_pct', 'inflation_rate_pct_chg', 'interest_rate_pct_chg', and 'gspc_prev_year_pct_chg' are helpful in separating the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab7227",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfae1b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Preprocessing Data\n",
    "The dataset comprises records for 808 months, with each row featuring a crucial predictor for the corresponding month. Additionally, it indicates whether there was an increase or decrease in the S&P 500 index, denoted by the values `True` or `False`.\n",
    "\n",
    "We find numeric features are: `inflation_rate_pct`, `interest_rate_pct`, `inflation_rate_pct_chg`, `interest_rate_pct_chg`, `gspc_prev_year_pct_chg`. Since there is no missing values, imputation is not necessary. As the characteristics were exclusively numerical, we utilized a StandardScaler to guarantee the normalization of feature matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71d14c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Predicting exact stock prices is challenging, so we simplify the task by transforming it into a binary classification problem—predicting whether the stock price will increase or decrease. Our focus is on identifying whether there is an increase in the S&P 500 index, making it a binary classification problem. To tackle this, we utilize Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c3cc5-a62a-4ae7-ad3d-b17e56f858df",
   "metadata": {},
   "source": [
    "```{glue:figure} regression_mean_test_score\n",
    "---\n",
    "width: 400px\n",
    "name: \"regression_mean_test_score\"\n",
    "---\n",
    "Present results of logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a0b04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The test data of logistic regression yields an precision of {glue:text}`regression_mean_test_score`%. Precision is calculated as the number of true positives divided by the sum of true positives and false positives. Nevertheless, caution is necessary when interpreting this metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4dda23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Dummy Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedec99-4f29-4d1a-bdf1-ac9e0da857fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{glue:figure} dummy_mean_test_score\n",
    "---\n",
    "width: 400px\n",
    "name: \"dummy_mean_test_score\"\n",
    "---\n",
    "Present results of dummy model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec3911",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Discussion\n",
    "\n",
    "In concluding this report, we express gratitude for the valuable input received from four reviewers and aim to address significant queries in the discussion section.\n",
    "\n",
    "### Possible Reasons for Worse Performance of the Logistic Regression Model over Dummy Model\n",
    "The quality of the data, including missing values, outliers, or noise, can significantly impact the performance of any predictive model. If the data is noisy or contains irrelevant information, the model's accuracy may suffer. Stock price movements are influenced by a wide range of factors, and if the model does not have access to relevant information, it may struggle to make accurate predictions.\n",
    "\n",
    "### Motivation of Picking the Logistic Regression Model\n",
    "Logistic regression is specifically designed for binary classification problems where the outcome variable is dichotomous, meaning it has two possible classes (e.g., 0 or 1, true or false, positive or negative). The coefficients in logistic regression represent the log-odds of the target variable, making it easy to interpret the impact of each feature on the likelihood of a particular outcome. This interpretability is valuable for understanding the relationships between variables.\n",
    "\n",
    "\n",
    "### Overall\n",
    "The model training is designed such that it follows the Golden Rule, which refers to \"despite our utmost concern for test error, it is crucial to emphasize that the training phase must remain completely unaffected by the test data.\" The test data of dummy regression yields a precision of {glue:text}`dummy_mean_test_score`%. The precision of dummy regression is better then the precision of logistic regression. In the preceding examination, we utilize `Logistic Regression` and `Dummy Regression`. Consequently, the result does not show advantage of `Logistic Regression` over `Dummy Regression`. (see {glue:text}`result_df`%) Further data preprocessing is needed to enhance the overall effectiveness of the model. This is aligned with expectation, because we do not have enough meaningful features to extract information that is helpful for a more accurate categorization. Also, we have imbalanced classes, which can also prevent the model from determining whether the index will grow. \n",
    "\n",
    "The model's performance may be sensitive to hyperparameter settings, therefore it can be helpful to improve the model performance to experiment with different configurations through hyperparameter tuning. In the future, to improve the performance of the model, we may want to consult with specialists of finance field to get more key information about the topic. This will allow more features to be added to the data and positively impact the model training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f695fb7-c97a-449c-8c19-7b56b4ba420d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{glue:figure} result_df\n",
    "---\n",
    "width: 400px\n",
    "name: \"result_df\"\n",
    "---\n",
    "Comparison of Dummy model and Logistic Regression Score on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c78fe1-50f2-4272-8a8c-2e29415461ba",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025420cb-e570-42a8-9e57-6ba692e5f61b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{bibliography}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8288f4-16d1-4bff-b4eb-076bc189651e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "522Group3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
